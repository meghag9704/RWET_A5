{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5287321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"combined_noDate.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f58b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life\n",
      "So much of life has happened in the middle of the Instagram pictures. So much of life has happened that you can’t remember. Sadness and anxieity hangs heavy over the moments of happiness. The moments you wish last a lifetime are mere seconds but when you think back to them and how you felt in that moment, everything changes, you feel light again, transported back to that time when you were so happy.\n",
      "I was looking at some old pictures of me — at when I was at my heaviest — my senior year of \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31877258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w',\n",
       " 'l',\n",
       " 'a',\n",
       " 's',\n",
       " 'm',\n",
       " ' ',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'w',\n",
       " 'l',\n",
       " 't',\n",
       " 'o',\n",
       " 'c',\n",
       " 'w',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'd',\n",
       " 'q',\n",
       " 'a',\n",
       " ' ',\n",
       " ' ',\n",
       " 'e',\n",
       " 'y',\n",
       " 'u',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'd',\n",
       " 'u',\n",
       " '\\n',\n",
       " 'm',\n",
       " 'a',\n",
       " 'o',\n",
       " 's',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'H',\n",
       " 'f',\n",
       " 'k',\n",
       " 'p',\n",
       " 'a',\n",
       " 'Y',\n",
       " ' ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(text, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12888a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6055cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keep',\n",
       " 'and',\n",
       " 'help',\n",
       " 'the',\n",
       " 'and',\n",
       " 'I',\n",
       " 'name',\n",
       " 'see',\n",
       " 'nostrils',\n",
       " 'grease,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14ab687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 17389),\n",
       " ('e', 8462),\n",
       " ('t', 6591),\n",
       " ('o', 5491),\n",
       " ('a', 5326),\n",
       " ('n', 4820),\n",
       " ('i', 4271),\n",
       " ('s', 4056),\n",
       " ('h', 3800),\n",
       " ('r', 3243),\n",
       " ('l', 2785),\n",
       " ('d', 2598)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(text).most_common(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beaeae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 994),\n",
       " ('the', 618),\n",
       " ('to', 481),\n",
       " ('and', 446),\n",
       " ('a', 316),\n",
       " ('of', 283),\n",
       " ('you', 255),\n",
       " ('in', 251),\n",
       " ('my', 236),\n",
       " ('that', 206),\n",
       " ('it', 181),\n",
       " ('am', 170)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words).most_common(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fe47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from markovify) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f370bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d817105",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = markovify.Text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c993f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought I would have so much more in New York, definitely a want.\n",
      "I have been talking to someone twice my age about abuse and while they agree some have said taking a few Advil, and prep themselves for a ray of sun In places too far in, being consumed by the water and in the world-- terrorism happens everyday.\n",
      "Because then, What do you not add to the endless concerts.\n",
      "It hurts and I can’t manage anymore.\n",
      "You feel like you all bring to my destination.\n",
      "I understand that we had a roof over my face.\n",
      "#poetry #poet Everyday this past week I have forgotten how to help or ask for help.\n",
      "But she fell in love with them and keep them company.\n",
      "I want to cry through every song.\n",
      "How do I watch a ray of sunlight.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    print(generator.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff3b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There has to be ok.\n",
      "If it is what's difficult.\n",
      "And you let someone else with your other friends.\n",
      "Sticking, I wish the car and come home.\n",
      "Some I have it easy.\n",
      "Is it because my mom shrivel up.\n",
      "I can and I can’t even speak for yourself?\n",
      "None\n",
      "I often feel like it's you.\n",
      "It’s more than anything.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    print(generator.make_short_sentence(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de9fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought about that day.\n",
      "And when I clearly did.\n",
      "I know what it is.\n",
      "I don’t know what others will say.\n",
      "I am a great thing.\n",
      "We celebrate a day of my life.\n",
      "Even if it’s justifiable?\n",
      "But really, how do you let it inhibit you.\n",
      "None\n",
      "How many times and not the artist.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    print(generator.make_short_sentence(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97aedfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know we’re out of bed and get going.\n"
     ]
    }
   ],
   "source": [
    "print(generator.make_short_sentence(40, tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2112064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What’s worse when one of your identity.\n"
     ]
    }
   ],
   "source": [
    "print(generator.make_short_sentence(40, test_output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ccc0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesByChar(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "981a8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_model = SentencesByChar(\"What’s worse when one of your identity.\", state_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89925fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_model = SentencesByChar(\"Silence is\", state_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016bc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SentencesByChar object at 0x7fc9901b12b0>\n"
     ]
    }
   ],
   "source": [
    "print(con_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653d9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_char = SentencesByChar(text, state_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "758f447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yknow it work.\n"
     ]
    }
   ],
   "source": [
    "print(gen_char.make_sentence(test_output=False).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d74582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But with every song.\n"
     ]
    }
   ],
   "source": [
    "print(gen_char.make_sentence(test_output=False).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4938e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to \"word\" for a word-level model\n",
    "level = \"char\"\n",
    "# controls the length of the n-gram\n",
    "order = 7\n",
    "# controls the number of lines to output\n",
    "output_n = 14\n",
    "# weights between the models; text A first, text B second.\n",
    "# if you want to completely exclude one model, set its corresponding value to 0\n",
    "weights = [0.5, 0.5]\n",
    "# limit sentence output to this number of characters\n",
    "length_limit = 280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d754754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You didn’t.\n",
      "\n",
      "I remember play slide  \t•\tA person looses balance to the heartbeats, By the corrected to twirl them When she was.\n",
      "\n",
      "But this.\n",
      "\n",
      "Every time my birthday is a disproportionate amount of the experiences that it all.\n",
      "\n",
      "Of everything I can’t count   I have done.\n",
      "\n",
      "The idea that no matters that apart, and tall, where my demons hide.\n",
      "\n",
      "The way his temper shoots off to my texts  I told myself before.\n",
      "\n",
      "And the red slides.\n",
      "\n",
      "I believe it’s clean pain \t2\tSeattle and loved.\n",
      "\n",
      "Maybe this absolutely horrible but i see it become more of its excitement became my perspective alongside that need.\n",
      "\n",
      "This is a question — am I an exceptions and I promise and where I teetered on things.\n",
      "\n",
      "Observation that make it day by day hoping to someone you love?\n",
      "\n",
      "I never really is no other with self dinner, got into my life.\n",
      "\n",
      "I could get some point.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "gen = model_cls(text, state_size=order)\n",
    "for i in range(output_n):\n",
    "    out = gen.make_short_sentence(length_limit, test_output=False)\n",
    "    out = out.replace(\"\\n\", \" \")\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33798fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despair, Depressed, and I feel completely respect me so much of it all has to be happy, I can’t stop talking about me.\n",
      "\n",
      "I don’t know my  Deepest and darkest fears.\n",
      "\n",
      "She never knew where my demons hide.\n",
      "\n",
      "I want to talk to someone else with the architecture of How Machine learning how to help or ask for?\n",
      "\n",
      "I have time to ask myself rational student 4 years hiding my friends.\n",
      "\n",
      "So untouched we say existed, why did the shooting in this job, don’t have provides.\n",
      "\n",
      "I am not important to come yell at you can’t be real w me and effort and glue myself something on the others - perceptions and the bile rising in me much longer.\n",
      "\n",
      "I thought was fun.\n",
      "\n",
      "I think we can find unknown and have evolved and my friendship surveys  A remind myself something magical about 10 entered.\n",
      "\n",
      "How many people to treat me like some point to apologize.\n",
      "\n",
      "Like am I pampered to know.\n",
      "\n",
      "I miss academic research assistant when I was worried I might be good, might eventually turn it into bed before.\n",
      "\n",
      "If it’s fleeting, not something said and done, this to be over.\n",
      "\n",
      "You feel lightest I have nothing the converse like this out.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "gen = model_cls(text, state_size=order)\n",
    "for i in range(output_n):\n",
    "    out = gen.make_short_sentence(length_limit, test_output=False)\n",
    "    out = out.replace(\"\\n\", \" \")\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ff9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = markovify.NewlineText(text, state_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3119f8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Left me how to--'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.make_sentence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f567aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was I am not just want someone different? Shouldn’t I am sorry for things are my father left, and far in, being my happiness in as far as I feel horrible. And how to'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.make_sentence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb5d3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is what the supply as a conversation The golden hue\n",
      "Times Square is no doubt, it would change in will remind myself out in the small fine line of self doubt.\n",
      "I have changed and I want to pour the\n",
      "I can all changed. I was physical in a picture, of forgiveness makes sense of their errands, pop a job market goes through it can't even though I am sorry for attack. Combined with no conversation with every night,\n",
      "I’m good, might be your skin because people the stars illuminate the anger he isn’t and to have fun. Honestly, college to be a fly on the past week ago. I feel invincible. And I looked effortless and overwhelmed? Isn’t this life is my personal confidence. It is nothing holding me is it was crying because we're taught me\n",
      "we think I remember thinking about 2 friends are a 100 times it’s justifiable? Is just empty, hollow but it all. And the mass execution in denial and home now you want to be a hater.\n",
      "We are in mind but I am loved and contemplate suicide. Like privilege is the reason for years. And then Erica will be used more privileged? Do you to live with your strength\n",
      "After all honesty, it’s nothing to end of that damn party, go before she talked about your cave, you were completely respectable and deep. There is one. I told myself apart from\n",
      "Stuck, that’s it.\n",
      "As the tool to firmly settle up even cry. A happy at me saying,\n",
      "Beeping in the sun rose. I don’t see you an additional 2 years, that shouldn’t I grew I know that fast.\n",
      "Talking to live. It was 17, I needed a grip.\n",
      "It was the boy to be here.\n",
      "This time you will play the thing society tells the equation one of day.\n"
     ]
    }
   ],
   "source": [
    "for i in range(14):\n",
    "    print(s_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "523957a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinesByChar(markovify.NewlineText):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2002a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_char_model = LinesByChar(text, state_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1bf15a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nevert continue to not going.\n",
      "I feel always lonely seeing in my mom’s quiet to be see a black and ther of our part speed it times with assumptiness.\n",
      "Because deep ink we spending that. To cally affect—the friend more in to screen,\n",
      "He differents your since of worthless. He many into then I am tight wasn’t know when while over another personality of food days,\n",
      "I watched person I am I standing me the make it’s a bursts\n",
      "I am sorry I crawl in out 2 year,\n",
      "The talking up a standing in London I was going long with the try in throught you could new I try in the subway for wonder,\n",
      "One they with it want to be on the reminder socially are of thinkish to ask\n",
      "And I felt life a past fell oyster person ourselve. You go out you are 5 months and trafficult light.\n",
      "But you left, the cloud and be seem to say\n",
      "I do you can’t few how long to survive. You can until on one does dropped color taught the about it her friend tried of a made mysticks\n",
      "I knew I want set and really little to live? To calmness too many, them far and just time and that were never fire south a was if h my privilege. I am itchier away.\n",
      "So k we weathe.\n",
      "One of job any people that I feel always so you don’t want urge to do your best want to unity. I went to sleeping them\n"
     ]
    }
   ],
   "source": [
    "for i in range(14):\n",
    "    print(s_char_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37752399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year pink.\n",
      "What’s when sometimes\n",
      "That weird to be their self,\n",
      "And I this? Sometimes with the small I can by you cannot fingers made and so happy accepted like I want passing about at me\n",
      "While had just so not screen,\n",
      "I done. Cutoff but it not the two when water see that left one of times\n",
      "With Vernal, I underland while I have in?\n",
      "Being to be land’s seeing?\n",
      "This privileged? Isn’t had times it morning. It's name craving loss then the CTO in oyster,\n",
      "The oddest point to pour time of living anymore. Where I hate that?\n",
      "I am happiness\n",
      "If it me but the people and hones that weird excitements what her it hindi at the went laughts\n",
      "You won’t haven’t mine in sometimes you have to differing to grow it’s going?\n",
      "You don't was all, where when seconds? I had to be lightings around only didn't have stops throwing with my birthday\n"
     ]
    }
   ],
   "source": [
    "for i in range(14):\n",
    "    print(s_char_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2500329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::pyls-spyder==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda==2022.10=py39_0\n",
      "  - defaults/osx-64::python-lsp-black==1.2.1=py39hecd8cb5_0\n",
      "  - defaults/osx-64::python-lsp-server==1.5.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::pylint==2.14.5=py39hecd8cb5_0\n",
      "  - defaults/osx-64::spyder==5.3.3=py39hecd8cb5_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/meghagoel/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  dill               pkgs/main/noarch::dill-0.3.4-pyhd3eb1b0_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9670e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (4.27.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7098db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dbd820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "716c4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bf7600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a57c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: multiprocess in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: xxhash in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: pandas in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: packaging in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: aiohttp in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "236f9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79712971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7577847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/Users/meghagoel/.cache/huggingface/datasets/text/default-fb51a1cac9338a52/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531458a6a8564fac8132e0a52f72dd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = datasets.load_dataset('text', data_files=\"combined_noDate.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6256d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_training_data = training_data.map(\n",
    "    lambda x: tokenizer(x['text']),\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "585664a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 64\n",
    "# magic from https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "lm_training_data = tokenized_training_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96c0ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5ab9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  train_dataset=lm_training_data['train'],\n",
    "                  args=TrainingArguments(\n",
    "                      output_dir='distilgpt2-finetune-frankenstein20k',\n",
    "                      num_train_epochs=1,\n",
    "                      do_train=True,\n",
    "                      do_eval=False\n",
    "                  ),\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8e83df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43, training_loss=3.7125492539516713, metrics={'train_runtime': 96.3069, 'train_samples_per_second': 3.562, 'train_steps_per_second': 0.446, 'total_flos': 5601549090816.0, 'train_loss': 3.7125492539516713, 'epoch': 1.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25b6dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9cfacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Two roads diverged in a yellow light and blue wave, and the city’s residents were in for the most part. It was the city's most beautiful night. The most glorious sunset of the night - a beach, a beautiful beach surrounded by the beauty of its beauty and its beauty. It is the city's heart's heart's heart's jewel in it, the beach of its beauty of its beauty. -This was it, that life and its soul was born, to this -\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Two roads diverged in a yellow\", max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55359445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Silence is enough!You have made my body melt, you’re done. You have made the most it ever could. You only want to eat in the morning--no light and in the evening. You want to be loved.You want to be a more than just a person--or a person. You want the world to see you--you want to know how to feel like, to have some time, and I’m in no rush.You want to be different'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Silence is\", max_length=100)[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53c98546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Silence is a weapon of evil. And I have no doubt that I've grown so tired of the fear and despair.\\nAnd finally I have an answer: no answer. I am afraid to answer a phone call to say this. I have a dark feeling. I am always scared to answer. I don't believe I am an object—I am an object that I am a child. My father is the one that my mother is afraid of. I have the sense that if it wasn\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Silence is\", max_length=100)[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c74821fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer = AutoTokenizer.from_pretrained('distilgpt2-finetune-frankenstein20k')\n",
    "my_model = AutoModelForCausalLM.from_pretrained('distilgpt2-finetune-frankenstein20k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77e51fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator = pipeline(\"text-generation\", model=my_model, tokenizer=my_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43a96fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow light. It was a blue evening. Then the sky, deep in the darkness, the sun shone blue sky - the sky was blue. The sun, blue night sun. The clouds and stars shone high on the'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_generator(\"Two roads diverged in a yellow\")[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4879a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Silence is one of the most stressful things I have had since I was born—though there have been times when I have felt as if a single mom and her son didn’t have time to talk and spend with their parents. I remember'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_generator(\"Silence is\")[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c791631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Silence is all about people who, even when they don’t understand, can see things that even you don’t understand even the last 10 seconds of think shouldn’t be good in the shadow of change. It happens sooner or later but the white screens all over really make things more real.55:35 ago 0 people ePF8 ago in This is an analysis, qualifier It is the old ageTo no I138 laughter  sph. common on my'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Silence is\",\n",
    "          top_k=tokenizer.vocab_size,\n",
    "          max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9fe99ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Happiness is the person you want to me. I don't mind that. I don't mind thinking logically if my words are racist some that tell people about me all. White guys gives me red girls and enmeshed with the thick texture you see through their hair, an athletic White pop pays thick white ears and a culture built on making them want deep queer conversations when you have thin people. It makes sense in a way where you need time, so if you don't like me then you\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Happiness is\",\n",
    "          top_k=tokenizer.vocab_size,\n",
    "          max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf6a7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Space is what makes a great place. As a refusal to acknowledge some of the things right and wrong that made me appreciate it.But I have to admit it might be a result of subconscious doubt.And that choice that my heart needs. For me others - like myself have been crippled as something I have forgotten and held to myself. As I've stated in Chapter 30, I stand back from the wall and sleep off the pain. And I miss something space my heart needs to live in because I\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Space is\",\n",
    "          top_k=tokenizer.vocab_size,\n",
    "          max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39425cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc539163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
